# ETL ‚Äì Teste Analista de Dados (Pentaho + PostgreSQL)

> Autor: Gessiel Silva Passos

Este reposit√≥rio cont√©m uma solu√ß√£o de ETL completa usando **Pentaho Data Integration (PDI/Spoon)** e **PostgreSQL** para integrar dados de pessoas, √≥rg√£os, endere√ßos e v√≠nculos, com **valida√ß√µes de qualidade**, **relat√≥rio de erros**, **m√©tricas de execu√ß√£o**, **idempot√™ncia** (reprocessamento sem duplicidade) e **job de orquestra√ß√£o**.

## üì¶ Conte√∫do
```
/docs
  README.md           ‚Üê este arquivo
  ARQUITETURA.md      ‚Üê desenho l√≥gico, decis√µes e fluxos
/sql
  01_ddl.sql          ‚Üê cria√ß√£o das tabelas destino + apoio
/kettle
  j01_principal.kjb   ‚Üê job principal (orquestra as 4 transforma√ß√µes)
  t01_pessoa.ktr
  t02_orgao.ktr
  t03_endereco.ktr
  t04_vinculo.ktr
/input
  pessoas.csv
  orgaos.csv
  enderecos.csv
  vinculos.csv
/logs                  ‚Üê destino dos logs (csv + kitchen)
```

> **Observa√ß√£o**: os arquivos *.ktr/*.kjb n√£o est√£o versionados aqui; devem ser salvos pelo Spoon nesse caminho `kettle/` com os nomes acima. Os CSVs de exemplo devem ser colocados em `/input`.

## üóÑÔ∏è Banco de Dados
Execute o script de DDL antes de rodar o ETL:
```bash
psql -h <host> -U <user> -d <db> -f sql/01_ddl.sql
```

## ‚öôÔ∏è Par√¢metros (usar no Spoon e no Kitchen)
- `P_INPUT_DIR` ‚Üí caminho dos arquivos de entrada (ex.: `C:\Pentaho\ETL_PESSOAS_PENTAHO\dados_entrada` ou `<repo>/input`)
- `P_LOG_DIR` ‚Üí caminho de logs (ex.: `C:\Pentaho\ETL_PESSOAS_PENTAHO\logs` ou `<repo>/logs`)
- `ARQ_PESSOAS` ‚Üí `pessoas.csv`
- `ARQ_ORGAOS` ‚Üí `orgaos.csv`
- `ARQ_ENDERECOS` ‚Üí `enderecos.csv`
- `ARQ_VINCULOS` ‚Üí `vinculos.csv`

Nos passos *CSV Input* referencie `${P_INPUT_DIR}/${ARQ_*}` e nos *Text File Output* de erros `${P_LOG_DIR}/erros_<tabela>.csv`.

## üö¶ Ordem de execu√ß√£o
1. `t01_pessoa.ktr`  
2. `t02_orgao.ktr`  
3. `t03_endereco.ktr`  
4. `t04_vinculo.ktr`  

> Ligue em sequ√™ncia no `j01_principal.kjb` com **On Success**. Opcional: **Abort** em **On Failure**.

## ‚ñ∂Ô∏è Executando no Spoon
- Abra o **j01_principal.kjb**
- Em cada *Job ‚Üí Transformation*, marque **Pass parameters to transformation**
- Defina os par√¢metros no Job (menu **Edit ‚Üí Settings ‚Üí Parameters**)
- Rode o Job e verifique os *Step Metrics* e o console

## üñ•Ô∏è Executando em linha de comando (Kitchen)
Windows:
```bat
Kitchen.bat -file:"C:\caminho\para\kettle\j01_principal.kjb" -level=Basic ^
  -param:P_INPUT_DIR="C:\Pentaho\ETL_PESSOAS_PENTAHO\dados_entrada" ^
  -param:P_LOG_DIR="C:\Pentaho\ETL_PESSOAS_PENTAHO\logs" ^
  -param:ARQ_PESSOAS="pessoas.csv" ^
  -param:ARQ_ORGAOS="orgaos.csv" ^
  -param:ARQ_ENDERECOS="enderecos.csv" ^
  -param:ARQ_VINCULOS="vinculos.csv" ^
  -logfile "C:\Pentaho\ETL_PESSOAS_PENTAHO\logs\job_%Y-%m-%d_%H%M%S.log"
```

Linux:
```bash
./kitchen.sh -file="/caminho/para/kettle/j01_principal.kjb" -level=Basic   -param:P_INPUT_DIR="/dados/entrada"   -param:P_LOG_DIR="/logs"   -param:ARQ_PESSOAS="pessoas.csv"   -param:ARQ_ORGAOS="orgaos.csv"   -param:ARQ_ENDERECOS="enderecos.csv"   -param:ARQ_VINCULOS="vinculos.csv"   -logfile "/logs/job_%Y-%m-%d_%H%M%S.log"
```

## ‚úÖ O que esta solu√ß√£o cobre
- **Normaliza√ß√£o** em tabelas relacionais
- **Integridade** com PK, FK, UNIQUE conforme aplic√°vel
- **Padroniza√ß√£o** e valida√ß√£o de dados (JS no *Modified JavaScript Value*)
- **Relat√≥rio de erros** em CSV (`/logs`) e tabela `etl_erros`
- **M√©tricas** por execu√ß√£o na tabela `etl_metricas`
- **Idempot√™ncia** (Insert/Update) e **retomada** segura

## üîç Checks r√°pidos
```sql
-- 1) Rodar 2x e n√£o duplicar
SELECT COUNT(*) FROM pessoa;
SELECT COUNT(*) FROM orgao;
SELECT COUNT(*) FROM endereco;
SELECT COUNT(*) FROM vinculo;

-- 2) Integridade referencial
SELECT p.* FROM pessoa p
LEFT JOIN orgao o ON o.sigla = p.sigla_orgao
WHERE o.sigla IS NULL AND p.sigla_orgao IS NOT NULL;

SELECT e.* FROM endereco e
LEFT JOIN pessoa p ON p.id_pessoa = e.id_pessoa
WHERE p.id_pessoa IS NULL;

SELECT v.* FROM vinculo v
LEFT JOIN pessoa p ON p.id_pessoa = v.id_pessoa
WHERE p.id_pessoa IS NULL;

-- 3) M√©tricas
SELECT * FROM etl_metricas ORDER BY data_execucao DESC LIMIT 10;

-- 4) Erros
SELECT * FROM etl_erros ORDER BY ts_erro DESC LIMIT 10;
```

## üß© D√∫vidas comuns
- **‚ÄúN√£o vejo o .ktr no seletor do Job‚Äù** ‚Üí confira a aba **General** do *Job Entry ‚Üí Transformation* e troque para **‚ÄúSpecify by filename‚Äù**, apontando para o caminho absoluto do `.ktr`.
- **‚ÄúKitchen diz que n√£o achou par√¢metros‚Äù** ‚Üí defina no **Job (n√≠vel do Job)** e marque **Pass parameters to transformation** em cada Job Entry.
---

**Boa sorte na apresenta√ß√£o!** Mostre o `j01_principal.kjb` rodando, as m√©tricas preenchidas e os relat√≥rios de erro. 
